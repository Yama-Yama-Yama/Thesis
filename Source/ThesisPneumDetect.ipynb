{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1Wo8JZXfoP9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAVT6brTw8mo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8WOp-pCf2j8"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/chest_xray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl3NIaQThO1E"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import keras\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization, Input, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, Callback, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "\n",
        "EPOCHS = 20\n",
        "INIT_LR = 0.000001\n",
        "IMG_SIZE = 224\n",
        "TITLES = ['PNEUMONIA', 'NORMAL']\n",
        "PATH = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B5pYBqAiIOR"
      },
      "outputs": [],
      "source": [
        "def get_data(data_dir):\n",
        "    data = []\n",
        "    \n",
        "    for title in TITLES:\n",
        "        print(f\"Loading {title} ...\")\n",
        "        path = os.path.join(data_dir, title)\n",
        "        class_number = TITLES.index(title)\n",
        "        for img_file in os.scandir(path):\n",
        "            if img_file.name == \".DS_Store\" or not img_file.is_file():\n",
        "                continue\n",
        "            try:\n",
        "                img_arr = cv2.imread(img_file.path, cv2.IMREAD_GRAYSCALE)\n",
        "                resized_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n",
        "                data.append([resized_arr, class_number])\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {img_file.name}: {e}\")    \n",
        "    print(f\"Finished loading {len(data)} images from {data_dir}.\")\n",
        "    \n",
        "    return np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM9CtliuiO7X"
      },
      "outputs": [],
      "source": [
        "train_data = get_data('train')\n",
        "test_data = get_data('test')\n",
        "val_data = get_data('val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvHzNiNlNcUq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "target_labels = [\"Pneumonia\", \"Normal\"]\n",
        "t = [target_labels[i[1]] for i in train_data]\n",
        "\n",
        "counts = [t.count(label) for label in target_labels]\n",
        "\n",
        "plt.pie(counts, labels=target_labels, autopct='%1.1f%%', textprops={'fontsize': 24})\n",
        "plt.title(\"Distribution of Target Labels\", fontsize=26)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-zII7TljqQX"
      },
      "outputs": [],
      "source": [
        "target_labels = [\"Pneumonia\", \"Normal\"]\n",
        "t = [target_labels[i[1]] for i in train_data]\n",
        "\n",
        "my_palette = sns.color_palette(['#9b59b6', '#3498db'])\n",
        "sns.set_palette(my_palette)\n",
        "\n",
        "sns.countplot(x=t)\n",
        "plt.xlabel('Class', fontsize=22)\n",
        "plt.ylabel('Count', fontsize=22)\n",
        "plt.title('Distribution of Classes', fontsize=26)\n",
        "plt.xticks(fontsize=18)\n",
        "plt.yticks(fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjIn8khsjqd7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(train_data[0][0], cmap='gray')\n",
        "plt.title(TITLES[train_data[0][1]], fontsize=22)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# Display last image in train_data with title\n",
        "plt.figure(figsize=(5, 5))  # Set plot size\n",
        "plt.imshow(train_data[-1][0], cmap='gray')  # Show image data\n",
        "plt.title(TITLES[train_data[-1][1]], fontsize=22)  # Set title based on class label\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK-uDD5Tjqlt"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = zip(*[(feature, title) for feature, title in train_data])\n",
        "X_val, y_val = zip(*[(feature, title) for feature, title in val_data])\n",
        "X_test, y_test = zip(*[(feature, title) for feature, title in test_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "662XcZ86jqoy"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train) / 255\n",
        "X_val = np.array(X_val) / 255\n",
        "X_test = np.array(X_test) / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UXOitK3jqrb"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_val = X_val.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "X_test = X_test.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlQsXKhejqtv"
      },
      "outputs": [],
      "source": [
        "data_mod = ImageDataGenerator(\n",
        "        featurewise_center=False, \n",
        "        samplewise_center=False,  \n",
        "        featurewise_std_normalization=False, \n",
        "        samplewise_std_normalization=False,  \n",
        "        zca_whitening=False,\n",
        "        rotation_range=20, \n",
        "        zoom_range=0.2,\n",
        "        width_shift_range=0.2, \n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False,\n",
        "        fill_mode='nearest')\n",
        "        \n",
        "data_mod.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM09u_Dp3hRt"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "def convolutional_block(x, filters, kernel_size, strides, dropout_rate):\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding='same', activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), strides=2, padding='same')(x)\n",
        "    return x\n",
        "\n",
        "def fully_connected_block(x, units, dropout_rate):\n",
        "    x = Dense(units, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "def create_model(input_shape=(224, 224, 1)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = convolutional_block(inputs, filters=32, kernel_size=(3, 3), strides=1, dropout_rate=0.0)\n",
        "    x = convolutional_block(x, filters=64, kernel_size=(3, 3), strides=1, dropout_rate=0.1)\n",
        "    x = convolutional_block(x, filters=64, kernel_size=(3, 3), strides=1, dropout_rate=0.0)\n",
        "    x = convolutional_block(x, filters=128, kernel_size=(3, 3), strides=1, dropout_rate=0.2)\n",
        "    x = convolutional_block(x, filters=256, kernel_size=(3, 3), strides=1, dropout_rate=0.2)\n",
        "    x = Flatten()(x)\n",
        "    x = fully_connected_block(x, units=128, dropout_rate=0.2)\n",
        "    outputs = Dense(units=1, activation='sigmoid')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def compile_model(model):\n",
        "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "def print_summary(model):\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQ5wHX1B3j1E"
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "compile_model(model)\n",
        "print_summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGQvvYMojqyg"
      },
      "outputs": [],
      "source": [
        "lrr = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=INIT_LR)\n",
        "\n",
        "chkpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "history = model.fit(data_mod.flow(X_train,y_train, batch_size = 32),\n",
        "                    epochs = 20,\n",
        "                    validation_data = data_mod.flow(X_val, y_val),\n",
        "                    callbacks = [lrr, chkpt])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rJmpN_Ey7TA"
      },
      "outputs": [],
      "source": [
        "model.load_weights('best_model_todate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UolGwXu1jq0z"
      },
      "outputs": [],
      "source": [
        "print(\"Loss of the model is - \" , model.evaluate(X_test, y_test)[0])\n",
        "print(\"Accuracy of the model is - \" , model.evaluate(X_test, y_test)[1]*100 , \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfylKY_6jq3H"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2)\n",
        "train_acc = history.history['accuracy']\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "fig.set_size_inches(20, 10)\n",
        "\n",
        "ax[0].plot(epochs, train_acc, 'go-', label='Training Accuracy')\n",
        "ax[0].plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "ax[1].plot(epochs, train_loss, 'g-o', label='Training Loss')\n",
        "ax[1].plot(epochs, val_loss, 'r-o', label='Validation Loss')\n",
        "ax[1].set_title('Training & Validation Loss')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eft0H7eO5N0"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('model20Epoch91AccLRRCHKPTES.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8jv4a0aQ_9H"
      },
      "outputs": [],
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "TITLES = [\"Pneumonia\", \"Normal\"]\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "conf_df = pd.DataFrame(conf_matrix, index=TITLES, columns=TITLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ878i1aRDfy"
      },
      "outputs": [],
      "source": [
        "conf_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBm12NeQjq5g"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(conf_df, cmap=\"YlOrBr\", linecolor='black', linewidth=1, \n",
        "            annot=True, fmt='g', cbar=False,\n",
        "            square=True, xticklabels=TITLES, yticklabels=TITLES, annot_kws={\"fontsize\": 22},\n",
        "            ax=ax)\n",
        "ax.set_xlabel('Predicted Class', fontsize=20)\n",
        "ax.set_ylabel('True Class', fontsize=20)\n",
        "ax.tick_params(axis='both', which='major', labelsize=20)\n",
        "plt.title(\"Confusion Matrix\", fontsize=24)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxWHkaDfkjs_"
      },
      "outputs": [],
      "source": [
        "model.save(\"model20Epoch91AccLRRCHKPTES.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYZMgUmEkkUE"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file = 'model_plot.png', show_shapes = True, show_layer_names = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
